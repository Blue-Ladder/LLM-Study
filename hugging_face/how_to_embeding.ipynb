{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.1.6 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (0.1.6)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain==0.1.6) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain==0.1.6) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain==0.1.6) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain==0.1.6) (0.6.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain==0.1.6) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.18 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain==0.1.6) (0.0.19)\n",
      "Collecting langchain-core<0.2,>=0.1.22 (from langchain==0.1.6)\n",
      "  Using cached langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langsmith<0.1,>=0.0.83 (from langchain==0.1.6)\n",
      "  Using cached langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain==0.1.6) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain==0.1.6) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain==0.1.6) (2.32.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain==0.1.6) (8.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.6) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.6) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.6) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.6) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.6) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.6) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.6) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.6) (2.1)\n",
      "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-core<0.2,>=0.1.22 (from langchain==0.1.6)\n",
      "  Using cached langchain_core-0.1.51-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached langchain_core-0.1.50-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached langchain_core-0.1.49-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached langchain_core-0.1.48-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached langchain_core-0.1.47-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached langchain_core-0.1.46-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached langchain_core-0.1.45-py3-none-any.whl.metadata (5.9 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached langchain_core-0.1.44-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached langchain_core-0.1.43-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached langchain_core-0.1.42-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached langchain_core-0.1.41-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached langchain_core-0.1.40-py3-none-any.whl.metadata (5.9 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached langchain_core-0.1.39-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached langchain_core-0.1.38-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.37-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.36-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.35-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.34-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.33-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.22->langchain==0.1.6) (4.2.0)\n",
      "  Using cached langchain_core-0.1.32-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.31-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.30-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.29-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.28-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.27-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.26-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.25-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.24-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.23-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langsmith<0.1,>=0.0.83 (from langchain==0.1.6)\n",
      "  Using cached langsmith-0.0.87-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.22->langchain==0.1.6) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.6) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.6) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.6) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.1.6) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.1.6) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.1.6) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.1.6) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.6) (3.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain==0.1.6) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.6) (1.0.0)\n",
      "Using cached langchain_core-0.1.23-py3-none-any.whl (241 kB)\n",
      "Using cached langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
      "Installing collected packages: langsmith, langchain-core\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.104\n",
      "    Uninstalling langsmith-0.1.104:\n",
      "      Successfully uninstalled langsmith-0.1.104\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.2.34\n",
      "    Uninstalling langchain-core-0.2.34:\n",
      "      Successfully uninstalled langchain-core-0.2.34\n",
      "Successfully installed langchain-core-0.1.23 langsmith-0.0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-openai 0.1.22 requires langchain-core<0.3.0,>=0.2.33, but you have langchain-core 0.1.23 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community==0.0.19 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (0.0.19)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain_community==0.0.19) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain_community==0.0.19) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain_community==0.0.19) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain_community==0.0.19) (0.6.7)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.21 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain_community==0.0.19) (0.1.23)\n",
      "Requirement already satisfied: langsmith<0.1,>=0.0.83 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain_community==0.0.19) (0.0.87)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain_community==0.0.19) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain_community==0.0.19) (2.32.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain_community==0.0.19) (8.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.19) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.19) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.19) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.19) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.19) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.19) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.19) (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.21->langchain_community==0.0.19) (4.2.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.21->langchain_community==0.0.19) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.21->langchain_community==0.0.19) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.21->langchain_community==0.0.19) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community==0.0.19) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community==0.0.19) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community==0.0.19) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community==0.0.19) (2024.7.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community==0.0.19) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community==0.0.19) (3.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.21->langchain_community==0.0.19) (1.3.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.21->langchain_community==0.0.19) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.21->langchain_community==0.0.19) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.21->langchain_community==0.0.19) (2.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.19) (1.0.0)\n",
      "Requirement already satisfied: langchain_core==0.1.23 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (0.1.23)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain_core==0.1.23) (6.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain_core==0.1.23) (4.2.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain_core==0.1.23) (1.33)\n",
      "Requirement already satisfied: langsmith<0.0.88,>=0.0.87 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain_core==0.1.23) (0.0.87)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain_core==0.1.23) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain_core==0.1.23) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain_core==0.1.23) (2.32.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain_core==0.1.23) (8.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from anyio<5,>=3->langchain_core==0.1.23) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from anyio<5,>=3->langchain_core==0.1.23) (1.3.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain_core==0.1.23) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain_core==0.1.23) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain_core==0.1.23) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain_core==0.1.23) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_core==0.1.23) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_core==0.1.23) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_core==0.1.23) (2024.7.4)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\doosa\\anaconda3\\lib\\site-packages (0.1.22)\n",
      "Collecting langchain-core<0.3.0,>=0.2.33 (from langchain-openai)\n",
      "  Using cached langchain_core-0.2.34-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain-openai) (1.41.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.33->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.33->langchain-openai) (1.33)\n",
      "Collecting langsmith<0.2.0,>=0.1.75 (from langchain-core<0.3.0,>=0.2.33->langchain-openai)\n",
      "  Using cached langsmith-0.1.104-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.33->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.33->langchain-openai) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.33->langchain-openai) (8.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.33->langchain-openai) (4.11.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.26.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.66.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.33->langchain-openai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.33->langchain-openai) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3.0,>=0.2.33->langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3.0,>=0.2.33->langchain-openai) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.40.0->langchain-openai) (0.4.6)\n",
      "Using cached langchain_core-0.2.34-py3-none-any.whl (393 kB)\n",
      "Using cached langsmith-0.1.104-py3-none-any.whl (149 kB)\n",
      "Installing collected packages: langsmith, langchain-core\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.0.87\n",
      "    Uninstalling langsmith-0.0.87:\n",
      "      Successfully uninstalled langsmith-0.0.87\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.1.23\n",
      "    Uninstalling langchain-core-0.1.23:\n",
      "      Successfully uninstalled langchain-core-0.1.23\n",
      "Successfully installed langchain-core-0.2.34 langsmith-0.1.104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.1.6 requires langchain-core<0.2,>=0.1.22, but you have langchain-core 0.2.34 which is incompatible.\n",
      "langchain 0.1.6 requires langsmith<0.1,>=0.0.83, but you have langsmith 0.1.104 which is incompatible.\n",
      "langchain-community 0.0.19 requires langchain-core<0.2,>=0.1.21, but you have langchain-core 0.2.34 which is incompatible.\n",
      "langchain-community 0.0.19 requires langsmith<0.1,>=0.0.83, but you have langsmith 0.1.104 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\doosa\\anaconda3\\lib\\site-packages (1.41.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: pypdf in c:\\users\\doosa\\anaconda3\\lib\\site-packages (4.3.1)\n",
      "Requirement already satisfied: sentence_transformers in c:\\users\\doosa\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from sentence_transformers) (4.44.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from sentence_transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from sentence_transformers) (2.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from sentence_transformers) (0.24.5)\n",
      "Requirement already satisfied: Pillow in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from sentence_transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.32.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (69.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2023.10.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from scikit-learn->sentence_transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.7.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\doosa\\anaconda3\\lib\\site-packages (1.8.0.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.0 in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\doosa\\anaconda3\\lib\\site-packages (from faiss-cpu) (23.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.1.6\n",
    "!pip install langchain_community==0.0.19\n",
    "!pip install langchain_core==0.1.23\n",
    "!pip  install langchain-openai\n",
    "!pip install openai\n",
    "!pip install pypdf\n",
    "!pip install sentence_transformers\n",
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다음 코드의 과정\n",
    "1. 문서 로드 (PyPDF 등)\n",
    "2. Text Splitter\n",
    "3. Text Embedding\n",
    "4. Vector Store\n",
    "5. Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가짜 뉴스를 판별하기 위한 인공지능 기법 적용 및 비교 분석  63\n",
      "이를 위해 본 연구에서는 가짜 뉴스를 판별하는 인공\n",
      "지능 기법들을 적용하여 비교 분석하는 연구를 진행하고 인공지능 기법 적용을 위한 입력값에 대한 분석과 인공지능 기법에 따른 비교 분석을 통해 자연어 처리 프로젝트에 인공지능 기법을 적용할 때 고려해야 할 점들에 대해 분석한다\n",
      ". 2장에서는 가짜 뉴스에 대한 연구\n",
      "와 뉴스 데이터 셋을 소개하며 본 연구에서 사용된 인공지능 기법에 대해 소개한다\n",
      ". 그리고 자연어 처리 방\n",
      "법에 대해 소개하여 본 연구를 위한 배경과 관련 연구를 제시한다\n",
      ". 3장에서는 본 연구의 프로세스와 진행 과\n",
      "정을 보여준다 . 4장에서는 실험 결과에 대한 분석을 진\n",
      "행하며 마지막으로 5장에서는 결론을 맺는다 .\n",
      "Ⅱ. 관련 연구 및 배경\n",
      "1. 가짜 뉴스\n",
      "가짜 뉴스는 사실과 다르거나 과장된 정보를 담고 있\n",
      "는 뉴스를 의미하며 이러한 뉴스는 종종 특정한 목적을 위해 의도적으로 생성되거나 확산될 수 있다\n",
      ". 가짜 뉴\n",
      "스 판별은 이러한 가짜 뉴스와 진짜 뉴스를 구별하는 과정을 의미하며 가짜 뉴스 탐지 및 판별에 대한 많은 연구들이 이루어지고 있다\n",
      ". 좌희정 외 (2019)의 연구에서\n",
      "는 자동화된 가짜 뉴스를 탐지하는 기술에 대한 개요와 함께 가짜 뉴스 탐지 시스템\n",
      ", 연구, 그리고 도전과제에 \n",
      "대해 소개하고 있다 . 그리고 Hamed 외(2023)의 연구에\n",
      "서는 가짜 뉴스에 대한 접근 방법 , 데이터 셋 , 특징 등\n",
      "을 분석하였다 . 이를 통해 가짜 뉴스에 대한 연구가 지\n",
      "속되고 있으며 , 가짜 뉴스를 구별하기 위한 접근 방법\n",
      "은 데이터 셋 , 가짜 뉴스 특징 추출 , 그리고 분류 모델 \n",
      "등의 연구로 이루어진다는 것을 알 수 있다 .\n",
      "가짜 뉴스 판별을 위한 모델을 만드는 것은 가짜 뉴\n",
      "스로 인한 피해를 줄이기 위한 토대를 마련할 수 있기 때문에 중요한 역할을 한다\n",
      ". 현윤진 외 (2018)의 연구에\n",
      "서는 가짜 뉴스로 인한 피해를 완화하기 위해 정부와 민간에서 대응을 하고 있지만\n",
      ", 가짜 뉴스의 탐지 모델\n",
      "이 뉴스만으로 진위 여부를 판별하는 한계와 편향성을 극복하기 위해 소셜 데이터도 활용하여 판별하는 방안을 제시하였다\n",
      ". 정이태 외 (2022)의 연구에서는 코로나 \n",
      "19와 관련된 가짜 뉴스를 판별하고자 하였다 . 가짜 뉴\n",
      "스 판별을 위해 그래프 데이터를 벡터 형태로 표현하여 객체 사이의 관계를 표현하는 방법인 \n",
      "Graph2vec 를 활\n",
      "용하였으며 사회적 참여 네트워크 내에서 정보전달 관계를 추가로 활용함으로써 효과적으로 코로나 19와 관련\n",
      "된 가짜 뉴스를 탐지하였다 . 이태원 외 (2023)의 연구에서\n",
      "는 감성 변화 패턴을 고려하여 합성곱 (Convolutional \n",
      "Neural Network, CNN) 에 기반한 딥러닝 모델을 제안\n",
      "하고 감성 변화 패턴이 기존 딥러닝 모델에 비해 가짜 뉴스 탐지 성능을 개선할 수 있음을 보였다\n",
      ". Verma 외\n",
      "(2021)은 기계 학습 (Machine Learning, ML) 분류 방법\n",
      "을 사용하여 가짜 뉴스를 탐지하기 위해 단어 임베딩\n",
      "(Word Embedding) 을 위한 WELFake 모델을 제시하고 \n",
      "기존의 머신러닝 모델에 적용하였다 . WELFake 모델은 \n",
      "글쓰기 패턴 , 문법, 심리 언어학적인 요소 , 그리고 양\n",
      "과 관련된 20가지 요소를 고려하여 구성되었다 . 이와 \n",
      "같이 가짜 뉴스를 판별하기 위한 방법으로 다양한 인공지능 기법들이 적용되고\n",
      ", 단어를 임베딩하는 방법 또\n",
      "한 가짜 뉴스를 판별하는 데 중요한 고려 사항이 됨을 알 수 있다\n",
      ".\n",
      "가짜 뉴스를 판별하기 위한 모델을 개발하기 위해서는 \n",
      "가짜 뉴스 데이터를 포함하는 데이터 셋이 필수적이다 . \n",
      "AI hub(2023) 에서는 한국어로 된 낚시성 기사 탐지 데이\n",
      "터를 제공하고 있으며 , SNU fackcheck(2023) 에서는 서울\n",
      "대학교 언론정보 연구소 등의 한국어로 된 가짜 뉴스  정\n",
      "보를 제공하고 있다 . 또한, WELFake_Dataset(Verma et \n",
      "al., 2021) 은 Kaggle, Reuter 등의 다양한 출처에서 종합\n",
      "적인 영어 뉴스 데이터를 csv 파일로 제공한다 . 이러한 \n",
      "가짜 뉴스 데이터는 한국어와 영어로 제공되며 , 이를 \n",
      "통해 다양한 연구가 진행되고 있다 .\n",
      "본 연구에서는 한국어 데이터의 양이 영어 데이터에 \n",
      "비해 적고 난이도 문제로 인해 영어 데이터를 선정하였다\n",
      ". 가짜 뉴스에 대한 연구 중에서 인공지능 기법과 단\n",
      "어 임베딩 방법에 따른 분석을 진행하기 위해 기존의 인공지능 기법 중 일부를 선정하고\n",
      ", 각각의 인공지능 \n",
      "기법과 단어 임베딩 방법에 대한 실험을 진행하여 가짜 뉴스를 판별하는 데 고려해야 할 점에 대해 분석한다\n",
      ".\n",
      "2. 인공지능 기법\n",
      "본 연구에서는 로지스틱 회귀 (Logistic Regression, \n",
      "LR), 나이브 베이즈 분류 (Naive Bayes Classification, \n",
      "NB), 랜덤 포레스트 (Random Forest, RF), 서포트 벡터 \n",
      "머신(Support Vector Machine, SVM), 퍼셉트론\n",
      "(Perceptron, PC), 그리고 순환 신경망 (Recurrent Neural \n",
      "Network, RNN) 등 6가지 인공지능 기법을 선정하여 \n",
      "실험을 진행하였다 .\n",
      "로지스틱 회귀는 데이터가 특정한 범주에 속할 확률\n"
     ]
    }
   ],
   "source": [
    "# pypdf를 통한  pdf 파일 로딩\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"C:\\\\Users\\\\doosa\\\\LLM_alpa_project\\\\hugging_face\\\\file\\\\test.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "print(pages[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CharacterTextSplitter는 특정 구분자를 기준으로 나눈다\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 100,\n",
    "    length_function = len,\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_documents(pages)\n",
    "\n",
    "print(texts[3].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "def get_embedding(text, model=\"heegyu/EEVE-Korean-Instruct-10.8B-v1.0-GGUF\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "print(get_embedding(\"Once upon a time, there was a cat.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doosa\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "\n",
    "def cos_sim(A, B):\n",
    "       return dot(A, B)/(norm(A)*norm(B))\n",
    "\n",
    "embeddings = hf.embed_documents(\n",
    "    [\n",
    "    \"today is monday\",\n",
    "    \"weather is nice today\",\n",
    "    \"what's the problem?\",\n",
    "    \"langhcain in useful\",\n",
    "    \"Hello World!\",\n",
    "    \"my name is morris\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "BGE_query_q = hf.embed_query(\"Hello? who is this?\")\n",
    "BGE_query_a = hf.embed_query(\"hi this is harrison\")\n",
    "\n",
    "print(cos_sim(BGE_query_q, BGE_query_a))\n",
    "print(cos_sim(BGE_query_q, embeddings[1]))\n",
    "print(cos_sim(BGE_query_q, embeddings[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"jhgan/ko-sbert-nli\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "ko = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "loader = PyPDFLoader(\"hugging_face\\\\file\\\\test.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "# split it into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"jhgan/ko-sbert-nli\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "ko = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
